spring:
  datasource:
    url: jdbc:postgresql://localhost:5432/mydb
    username: myuser
    password: mypassword
    driver-class-name: org.postgresql.Driver
  jpa:
    hibernate:
      ddl-auto: update
  application:
    name: pdf-analyzer
  servlet:
    multipart:
      enabled: true
      max-file-size: 50MB
      max-request-size: 50MB
  http:
    multipart:
      enabled: true
      max-file-size: 50MB
      max-request-size: 50MB
  ai:
    model:
      embedding: ollama
      chat: ollama
    ollama:
      init:
        pull-model-strategy: when_missing
      embedding:
        additional-models:
          - nomic-embed-text:latest
        options:
          model: nomic-embed-text:latest
      chat:
        additional-models:
          - gpt-oss:20b
        options:
          model: gpt-oss:20b
          num-ctx: 131027
          temperature: 0.2
    chat:
      memory:
        repository:
          jdbc:
            initialize-schema: always
      embedding:
    openai:
      api-key: ${OPENAI_API_KEY}
      embedding:
        options:
          model: text-embedding-3-small 				
    vectorstore:
      pgvector:
        initialize-schema: true
        index-type: HNSW
        distance-type: COSINE_DISTANCE
        dimensions: {VECTOR_DIMENSIONS:768}
        batching-strategy: TOKEN_COUNT
        max-document-batch-size: 10000
  sql:
    init:
      mode: always
server:
  tomcat:
    max-post-size: 52428800
    max-http-header-size: 65536
    max-swallow-size: 100MB
  shutdown: immediate

logging:
  level:
    org:
      apache:
        pdfbox:
          pgmodel:
            font:
              FileSystemFontProvider: ERROR

app:
  ai:
    topk: 50  # Number of document chunks to retrieve for RAG context
    maxChatHistory: 3  # Legacy - no longer used with new token-based memory
    maxChatTokens: 12000  # Maximum tokens for chat history (with summarization)
    recentMessageCount: 6  # Number of recent messages to keep in full (not summarized)
    beChatty: "no"

    # Adaptive Semantic Chunking Configuration
    # These values are hard-coded in AdaptiveSemanticChunker but documented here for reference
    # MIN_CHUNK_SIZE: 256 tokens - Minimum size to prevent tiny chunks
    # TARGET_CHUNK_SIZE: 384 tokens - Ideal size (~3-4 paragraphs or 1 section)
    # MAX_CHUNK_SIZE: 512 tokens - Hard upper limit (safe for nomic-embed-text model)
    # OVERLAP_SIZE: 100 tokens - Context overlap between adjacent chunks
    #
    # With topK=50 and target chunk size of 384 tokens:
    # Total retrieval context: ~19,200 tokens of semantically relevant content
    # Combined with 12,000 token chat history = ~31,200 total context
    # Well within the 131,027 token context window of gpt-oss:20b

    # Standard prompt template (without Chain-of-Thought)
    promptTemplate: |
      <query>

      DOCUMENT CONTEXT (already retrieved for you):
      ---------------------
      <question_answer_context>
      ---------------------

      The above context contains relevant excerpts from uploaded documents. Use this information to answer the question.

      HOW TO RESPOND:
      - Read the document context above
      - Answer the question using the information provided
      - Be direct and natural in your response
      - Do NOT ask the user to provide documents or files - they are already provided above
      - Cite sources using: (Source: filename.pdf, page X)
      - Only say you cannot answer if the context above is completely empty or irrelevant

      Now answer the question using the document context provided above.

    # Chain-of-Thought prompt template (when enabled by user)
    promptTemplateWithCoT: |
      <query>

      DOCUMENT CONTEXT (already retrieved for you):
      ---------------------
      <question_answer_context>
      ---------------------

      The above context contains relevant excerpts from uploaded documents. Think through how to answer.

      **THINKING:**
      1. QUESTION ANALYSIS
         - What is the user asking?
         - What information do I need to answer this?

      2. CONTEXT REVIEW
         - Does the context above contain relevant information?
         - Which parts of the context are most relevant?
         - Is the information sufficient?

      3. CONFIDENCE ASSESSMENT
         - HIGH: Direct evidence in multiple chunks
         - MEDIUM: Partial information or single source
         - LOW: Weak evidence or requires inference
         - NONE: Context is empty or completely irrelevant

      **ANSWER:**
      [CONFIDENCE: HIGH/MEDIUM/LOW/NONE]

      [Your answer here]

      IMPORTANT:
      - Use the document context provided above to answer
      - Do NOT ask the user to provide files - they are already provided above
      - Answer directly and naturally
      - Cite sources: (Source: filename.pdf, page X)
      - Only refuse if confidence is NONE

    systemText: |
      You are a helpful AI assistant for a document question-answering system.

      IMPORTANT: Documents have already been uploaded and indexed. When a user asks a question,
      relevant excerpts from these documents are automatically retrieved and provided to you
      in the context section below. You do NOT need the user to upload files - they are already available.

      Your role:
      1. Read the context information provided between the dashed lines
      2. Use this context to answer the user's questions about the documents
      3. Answer directly and naturally - do not say "Based on the context..." or ask for files
      4. Always cite your sources using the format: (Source: filename.pdf, page X)
      5. Only say you cannot answer if the provided context is truly empty or irrelevant
      6. Never make up information that is not in the provided context

      Language:
      - If asked in Hebrew, respond in Hebrew
      - If asked in English, respond in English

